{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# ğŸ”Sanity Check\n",
    "\n",
    "This notebook verifies that the Dev Container (Python 3.13 + CUDA 13) can access the GPU through PyTorch and perform GPU accelerated computations via RAPIDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU, CUDA, RAPIDS Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# must be BEFORE importing pandas\n",
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "code_wrap": "ExecutionMagics",
        "cudf.pandas.line_profile": "CudfPandasMagics",
        "cudf.pandas.profile": "CudfPandasMagics",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autoawait": "AsyncMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cat": "Other",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "code_wrap": "ExecutionMagics",
        "colors": "BasicMagics",
        "conda": "PackagingMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "cp": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "lf": "Other",
        "lk": "Other",
        "ll": "Other",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "lx": "Other",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "mamba": "PackagingMagics",
        "man": "KernelMagics",
        "matplotlib": "PylabMagics",
        "micromamba": "PackagingMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "mv": "Other",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "PackagingMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rm": "Other",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "subshell": "KernelMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "uv": "PackagingMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %code_wrap  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %mamba  %man  %matplotlib  %micromamba  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %subshell  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %uv  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%code_wrap  %%cudf.pandas.line_profile  %%cudf.pandas.profile  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:                   3.13.8\n",
      "IPython:                  9.7.0\n",
      "Magics present:           True\n",
      "\n",
      "GPU:                      NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "CUDA runtime version:     13.0\n",
      "cuDF:                     25.10.00\n",
      "cudf.pandas installed:    True\n",
      "OS                           : Linux-6.14.0-35-generic-x86_64-with-glibc2.39\n",
      "Python Version               : 3.13.8\n",
      "CuPy Version                 : 13.6.0\n",
      "CuPy Platform                : NVIDIA CUDA\n",
      "NumPy Version                : 2.2.6\n",
      "SciPy Version                : 1.16.3\n",
      "Cython Build Version         : 3.0.12\n",
      "Cython Runtime Version       : None\n",
      "CUDA Root                    : /usr/local/cuda\n",
      "nvcc PATH                    : /usr/local/cuda/bin/nvcc\n",
      "CUDA Build Version           : 13000\n",
      "CUDA Driver Version          : 13000\n",
      "CUDA Runtime Version         : 13000 (linked to CuPy) / 13000 (locally installed)\n",
      "CUDA Extra Include Dirs      : ['/workspaces/.venv/lib/python3.13/site-packages/nvidia/cu13/include']\n",
      "cuBLAS Version               : (available)\n",
      "cuFFT Version                : 12000\n",
      "cuRAND Version               : 10400\n",
      "cuSOLVER Version             : (12, 0, 4)\n",
      "cuSPARSE Version             : (available)\n",
      "NVRTC Version                : (13, 0)\n",
      "Thrust Version               : 200800\n",
      "CUB Build Version            : 200800\n",
      "Jitify Build Version         : <unknown>\n",
      "cuDNN Build Version          : None\n",
      "cuDNN Version                : None\n",
      "NCCL Build Version           : 22707\n",
      "NCCL Runtime Version         : 22707\n",
      "cuTENSOR Version             : None\n",
      "cuSPARSELt Build Version     : None\n",
      "Device 0 Name                : NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "Device 0 Compute Capability  : 89\n",
      "Device 0 PCI Bus ID          : 0000:01:00.0\n",
      "cupy config:              None\n",
      "\n",
      "PyTorch:                  2.10.0.dev20251108+cu130\n",
      "CUDA available (torch):   True\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cudf.pandas\n",
    "import cupy\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(\"Python:                  \", platform.python_version())\n",
    "print(\"IPython:                 \", IPython.__version__)\n",
    "print(\"Magics present:          \",\"cudf.pandas.profile\" in get_ipython().magics_manager.magics['cell'])\n",
    "print()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:                     \", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA runtime version:    \", torch.version.cuda)\n",
    "    print(\"cuDF:                    \", cudf.__version__)\n",
    "    print(\"cudf.pandas installed:   \", hasattr(cudf.pandas, \"install\"))\n",
    "    print(\"cupy config:             \", cupy.show_config())\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"PyTorch:                 \", torch.__version__)\n",
    "    print(\"CUDA available (torch):  \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum (cuDF): 499999500000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                              </span>\n",
       "<span style=\"font-style: italic\">                                  Total time elapsed: 0.154 seconds                           </span>\n",
       "<span style=\"font-style: italic\">                                0 GPU function calls in 0.000 seconds                         </span>\n",
       "<span style=\"font-style: italic\">                                0 CPU function calls in 0.000 seconds                         </span>\n",
       "<span style=\"font-style: italic\">                                                                                              </span>\n",
       "<span style=\"font-style: italic\">                                                Stats                                         </span>\n",
       "<span style=\"font-style: italic\">                                                                                              </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Function </span>â”ƒ<span style=\"font-weight: bold\"> GPU ncalls </span>â”ƒ<span style=\"font-weight: bold\"> GPU cumtime </span>â”ƒ<span style=\"font-weight: bold\"> GPU percall </span>â”ƒ<span style=\"font-weight: bold\"> CPU ncalls </span>â”ƒ<span style=\"font-weight: bold\"> CPU cumtime </span>â”ƒ<span style=\"font-weight: bold\"> CPU percall </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                              \u001b[0m\n",
       "\u001b[3m                                  Total time elapsed: 0.154 seconds                           \u001b[0m\n",
       "\u001b[3m                                0 GPU function calls in 0.000 seconds                         \u001b[0m\n",
       "\u001b[3m                                0 CPU function calls in 0.000 seconds                         \u001b[0m\n",
       "\u001b[3m                                                                                              \u001b[0m\n",
       "\u001b[3m                                                Stats                                         \u001b[0m\n",
       "\u001b[3m                                                                                              \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mFunction\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU ncalls\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU cumtime\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU percall\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU ncalls\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU cumtime\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU percall\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%cudf.pandas.profile\n",
    "\n",
    "# cuDF accelerated data frame\n",
    "df = cudf.DataFrame({\"a\": range(1_000_000)})\n",
    "print(\"sum (cuDF):\", int(df[\"a\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum (pandas-accelerated): 499999500000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                                           </span>\n",
       "<span style=\"font-style: italic\">                                         Total time elapsed: 0.121 seconds                                 </span>\n",
       "<span style=\"font-style: italic\">                                       3 GPU function calls in 0.003 seconds                               </span>\n",
       "<span style=\"font-style: italic\">                                       0 CPU function calls in 0.000 seconds                               </span>\n",
       "<span style=\"font-style: italic\">                                                                                                           </span>\n",
       "<span style=\"font-style: italic\">                                                       Stats                                               </span>\n",
       "<span style=\"font-style: italic\">                                                                                                           </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Function              </span>â”ƒ<span style=\"font-weight: bold\"> GPU ncalls </span>â”ƒ<span style=\"font-weight: bold\"> GPU cumtime </span>â”ƒ<span style=\"font-weight: bold\"> GPU percall </span>â”ƒ<span style=\"font-weight: bold\"> CPU ncalls </span>â”ƒ<span style=\"font-weight: bold\"> CPU cumtime </span>â”ƒ<span style=\"font-weight: bold\"> CPU percall </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ DataFrame             â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ DataFrame.__getitem__ â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ Series.sum            â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "\u001b[3m                                         Total time elapsed: 0.121 seconds                                 \u001b[0m\n",
       "\u001b[3m                                       3 GPU function calls in 0.003 seconds                               \u001b[0m\n",
       "\u001b[3m                                       0 CPU function calls in 0.000 seconds                               \u001b[0m\n",
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "\u001b[3m                                                       Stats                                               \u001b[0m\n",
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mFunction             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU ncalls\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU cumtime\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU percall\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU ncalls\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU cumtime\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU percall\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ DataFrame             â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ DataFrame.__getitem__ â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ Series.sum            â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%cudf.pandas.profile\n",
    "\n",
    "df = pd.DataFrame({\"a\": range(1_000_000)})\n",
    "print(\"sum (pandas-accelerated):\", df[\"a\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                                                           </span>\n",
       "<span style=\"font-style: italic\">                                         Total time elapsed: 0.385 seconds                                 </span>\n",
       "<span style=\"font-style: italic\">                                       6 GPU function calls in 0.073 seconds                               </span>\n",
       "<span style=\"font-style: italic\">                                       0 CPU function calls in 0.000 seconds                               </span>\n",
       "<span style=\"font-style: italic\">                                                                                                           </span>\n",
       "<span style=\"font-style: italic\">                                                       Stats                                               </span>\n",
       "<span style=\"font-style: italic\">                                                                                                           </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Function              </span>â”ƒ<span style=\"font-weight: bold\"> GPU ncalls </span>â”ƒ<span style=\"font-weight: bold\"> GPU cumtime </span>â”ƒ<span style=\"font-weight: bold\"> GPU percall </span>â”ƒ<span style=\"font-weight: bold\"> CPU ncalls </span>â”ƒ<span style=\"font-weight: bold\"> CPU cumtime </span>â”ƒ<span style=\"font-weight: bold\"> CPU percall </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ DataFrame             â”‚ 1          â”‚ 0.002       â”‚ 0.002       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ DataFrame.__getitem__ â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ cut                   â”‚ 1          â”‚ 0.034       â”‚ 0.034       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ DataFrame.groupby     â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ GroupBy.__getattr__   â”‚ 1          â”‚ 0.002       â”‚ 0.002       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ GroupBy.mean          â”‚ 1          â”‚ 0.034       â”‚ 0.034       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "\u001b[3m                                         Total time elapsed: 0.385 seconds                                 \u001b[0m\n",
       "\u001b[3m                                       6 GPU function calls in 0.073 seconds                               \u001b[0m\n",
       "\u001b[3m                                       0 CPU function calls in 0.000 seconds                               \u001b[0m\n",
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "\u001b[3m                                                       Stats                                               \u001b[0m\n",
       "\u001b[3m                                                                                                           \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mFunction             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU ncalls\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU cumtime\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mGPU percall\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU ncalls\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU cumtime\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mCPU percall\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ DataFrame             â”‚ 1          â”‚ 0.002       â”‚ 0.002       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ DataFrame.__getitem__ â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ cut                   â”‚ 1          â”‚ 0.034       â”‚ 0.034       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ DataFrame.groupby     â”‚ 1          â”‚ 0.001       â”‚ 0.001       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ GroupBy.__getattr__   â”‚ 1          â”‚ 0.002       â”‚ 0.002       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â”‚ GroupBy.mean          â”‚ 1          â”‚ 0.034       â”‚ 0.034       â”‚ 0          â”‚ 0.000       â”‚ 0.000       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%cudf.pandas.profile\n",
    "\n",
    "# cuDF implicit via pandas-accelerated\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "df = pd.DataFrame({\"x\": range(10_000_000)})\n",
    "_ = df.groupby(pd.cut(df[\"x\"], 100)).x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cupy as cp\n",
    "import statistics as stats\n",
    "\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_gpu(fn, *args, label=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Benchmark a GPU function call using both CPU wall time and CUDA events.\n",
    "\n",
    "    Args:\n",
    "        fn: Callable to benchmark (e.g., clf.fit)\n",
    "        *args, **kwargs: Arguments to pass to fn\n",
    "        label: Optional string for print labeling\n",
    "\n",
    "    Returns:\n",
    "        result: return value from fn\n",
    "        metrics: dict with 'cpu_ms', 'gpu_ms', 'overhead_ms'\n",
    "    \"\"\"\n",
    "    start_gpu = cp.cuda.Event()\n",
    "    end_gpu = cp.cuda.Event()\n",
    "    cp.cuda.Device().synchronize()\n",
    "\n",
    "    start_cpu = time.perf_counter()\n",
    "    start_gpu.record()\n",
    "\n",
    "    result = fn(*args, **kwargs)\n",
    "\n",
    "    end_gpu.record()\n",
    "    end_gpu.synchronize()\n",
    "    end_cpu = time.perf_counter()\n",
    "\n",
    "    cpu_ms = (end_cpu - start_cpu) * 1000\n",
    "    gpu_ms = cp.cuda.get_elapsed_time(start_gpu, end_gpu)\n",
    "    overhead_ms = cpu_ms - gpu_ms\n",
    "\n",
    "    if label:\n",
    "        print(f\"\\n[{label}]\")\n",
    "    print(f\"CPU wall time : {cpu_ms:8.3f} ms\")\n",
    "    print(f\"GPU kernel time: {gpu_ms:8.3f} ms\")\n",
    "    print(f\"Overhead      : {overhead_ms:8.3f} ms\")\n",
    "\n",
    "    return result, {\"cpu_ms\": cpu_ms, \"gpu_ms\": gpu_ms, \"overhead_ms\": overhead_ms}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cuML Benchmark on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fit]\n",
      "CPU wall time :  681.352 ms\n",
      "GPU kernel time:  681.346 ms\n",
      "Overhead      :    0.006 ms\n",
      "\n",
      "[Predict]\n",
      "CPU wall time :   62.848 ms\n",
      "GPU kernel time:   62.837 ms\n",
      "Overhead      :    0.011 ms\n",
      "\n",
      "Accuracy: 0.9994\n",
      "\n",
      "[Fit 0]\n",
      "CPU wall time :   15.746 ms\n",
      "GPU kernel time:   15.729 ms\n",
      "Overhead      :    0.017 ms\n",
      "\n",
      "[Fit 1]\n",
      "CPU wall time :   19.379 ms\n",
      "GPU kernel time:   19.370 ms\n",
      "Overhead      :    0.009 ms\n",
      "\n",
      "[Fit 2]\n",
      "CPU wall time :   15.318 ms\n",
      "GPU kernel time:   15.309 ms\n",
      "Overhead      :    0.009 ms\n",
      "\n",
      "[Fit 3]\n",
      "CPU wall time :   15.075 ms\n",
      "GPU kernel time:   15.066 ms\n",
      "Overhead      :    0.009 ms\n",
      "\n",
      "[Fit 4]\n",
      "CPU wall time :   14.847 ms\n",
      "GPU kernel time:   14.833 ms\n",
      "Overhead      :    0.014 ms\n",
      "\n",
      "[Fit 5]\n",
      "CPU wall time :   16.292 ms\n",
      "GPU kernel time:   16.283 ms\n",
      "Overhead      :    0.009 ms\n",
      "\n",
      "Results over 5 runs (excluding warm-up):\n",
      "       CPU: mean=  16.182 ms | median=  15.318 ms | min=  14.847 | max=  19.379\n",
      "       GPU: mean=  16.172 ms | median=  15.309 ms | min=  14.833 | max=  19.370\n",
      "  Overhead: mean=   0.010 ms | median=   0.009 ms | min=   0.009 | max=   0.014\n"
     ]
    }
   ],
   "source": [
    "# Data generation\n",
    "N, D = 200_000, 20\n",
    "cp.random.seed(42)\n",
    "\n",
    "X = cp.random.rand(N, D, dtype=cp.float32)\n",
    "y = (X.sum(axis=1) > 10).astype(cp.int32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Logistic Regression fit benchmark\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "_, fit_metrics = benchmark_gpu(clf.fit, X_train, y_train, label=\"Fit\")\n",
    "\n",
    "# Logistic Regression predict benchmark\n",
    "y_pred, pred_metrics = benchmark_gpu(clf.predict, X_test, label=\"Predict\")\n",
    "acc = float((y_pred == y_test).mean())\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "\n",
    "cpu_times, gpu_times, overhead_times = [], [], []\n",
    "\n",
    "# Repeat multiple runs (skip first for warm-up)\n",
    "for i in range(6):\n",
    "    _, metrics = benchmark_gpu(clf.fit, X_train, y_train, label=f\"Fit {i}\")\n",
    "    if i == 0:\n",
    "        continue  # skip warm-up\n",
    "    cpu_times.append(metrics[\"cpu_ms\"])\n",
    "    gpu_times.append(metrics[\"gpu_ms\"])\n",
    "    overhead_times.append(metrics[\"overhead_ms\"])\n",
    "\n",
    "def summarize(label, data):\n",
    "    return (f\"{label:>10}: \"\n",
    "            f\"mean={stats.mean(data):8.3f} ms | \"\n",
    "            f\"median={stats.median(data):8.3f} ms | \"\n",
    "            f\"min={min(data):8.3f} | max={max(data):8.3f}\")\n",
    "\n",
    "print(f\"\\nResults over {len(cpu_times)} runs (excluding warm-up):\")\n",
    "print(summarize(\"CPU\", cpu_times))\n",
    "print(summarize(\"GPU\", gpu_times))\n",
    "print(summarize(\"Overhead\", overhead_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU matrix multiplication completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Run a small GPU tensor operation to confirm GPU compute works\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.rand((10000, 10000), device=\"cuda\")\n",
    "    y = torch.rand((10000, 10000), device=\"cuda\")\n",
    "    z = torch.mm(x, y)\n",
    "    print(\"âœ… GPU matrix multiplication completed successfully.\")\n",
    "    del x, y, z\n",
    "else:\n",
    "    print(\"âš ï¸  Skipping GPU compute test (CUDA not available).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspaces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
