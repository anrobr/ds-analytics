{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# üîçSanity Check\n",
    "\n",
    "This notebook verifies that the Dev Container (Python 3.13 + CUDA 13) can access the GPU through PyTorch and perform GPU accelerated computations via RAPIDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU, CUDA, RAPIDS Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be BEFORE importing pandas\n",
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cudf.pandas\n",
    "import cupy\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(\"Python:                  \", platform.python_version())\n",
    "print(\"IPython:                 \", IPython.__version__)\n",
    "print(\"Magics present:          \",\"cudf.pandas.profile\" in get_ipython().magics_manager.magics['cell'])\n",
    "print()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:                     \", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA runtime version:    \", torch.version.cuda)\n",
    "    print(\"cuDF:                    \", cudf.__version__)\n",
    "    print(\"cudf.pandas installed:   \", hasattr(cudf.pandas, \"install\"))\n",
    "    print(\"cupy config:             \", cupy.show_config())\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"PyTorch:                 \", torch.__version__)\n",
    "    print(\"CUDA available (torch):  \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "\n",
    "# cuDF accelerated data frame\n",
    "df = cudf.DataFrame({\"a\": range(1_000_000)})\n",
    "print(\"sum (cuDF):\", int(df[\"a\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "\n",
    "df = pd.DataFrame({\"a\": range(1_000_000)})\n",
    "print(\"sum (pandas-accelerated):\", df[\"a\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "\n",
    "# cuDF implicit via pandas-accelerated\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "df = pd.DataFrame({\"x\": range(10_000_000)})\n",
    "_ = df.groupby(pd.cut(df[\"x\"], 100)).x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cupy as cp\n",
    "import statistics as stats\n",
    "\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_gpu(fn, *args, label=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Benchmark a GPU function call using both CPU wall time and CUDA events.\n",
    "\n",
    "    Args:\n",
    "        fn: Callable to benchmark (e.g., clf.fit)\n",
    "        *args, **kwargs: Arguments to pass to fn\n",
    "        label: Optional string for print labeling\n",
    "\n",
    "    Returns:\n",
    "        result: return value from fn\n",
    "        metrics: dict with 'cpu_ms', 'gpu_ms', 'overhead_ms'\n",
    "    \"\"\"\n",
    "    start_gpu = cp.cuda.Event()\n",
    "    end_gpu = cp.cuda.Event()\n",
    "    cp.cuda.Device().synchronize()\n",
    "\n",
    "    start_cpu = time.perf_counter()\n",
    "    start_gpu.record()\n",
    "\n",
    "    result = fn(*args, **kwargs)\n",
    "\n",
    "    end_gpu.record()\n",
    "    end_gpu.synchronize()\n",
    "    end_cpu = time.perf_counter()\n",
    "\n",
    "    cpu_ms = (end_cpu - start_cpu) * 1000\n",
    "    gpu_ms = cp.cuda.get_elapsed_time(start_gpu, end_gpu)\n",
    "    overhead_ms = cpu_ms - gpu_ms\n",
    "\n",
    "    if label:\n",
    "        print(f\"\\n[{label}]\")\n",
    "    print(f\"CPU wall time : {cpu_ms:8.3f} ms\")\n",
    "    print(f\"GPU kernel time: {gpu_ms:8.3f} ms\")\n",
    "    print(f\"Overhead      : {overhead_ms:8.3f} ms\")\n",
    "\n",
    "    return result, {\"cpu_ms\": cpu_ms, \"gpu_ms\": gpu_ms, \"overhead_ms\": overhead_ms}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cuML Benchmark on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation\n",
    "N, D = 200_000, 20\n",
    "cp.random.seed(42)\n",
    "\n",
    "X = cp.random.rand(N, D, dtype=cp.float32)\n",
    "y = (X.sum(axis=1) > 10).astype(cp.int32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Logistic Regression fit benchmark\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "_, fit_metrics = benchmark_gpu(clf.fit, X_train, y_train, label=\"Fit\")\n",
    "\n",
    "# Logistic Regression predict benchmark\n",
    "y_pred, pred_metrics = benchmark_gpu(clf.predict, X_test, label=\"Predict\")\n",
    "acc = float((y_pred == y_test).mean())\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "\n",
    "cpu_times, gpu_times, overhead_times = [], [], []\n",
    "\n",
    "# Repeat multiple runs (skip first for warm-up)\n",
    "for i in range(6):\n",
    "    _, metrics = benchmark_gpu(clf.fit, X_train, y_train, label=f\"Fit {i}\")\n",
    "    if i == 0:\n",
    "        continue  # skip warm-up\n",
    "    cpu_times.append(metrics[\"cpu_ms\"])\n",
    "    gpu_times.append(metrics[\"gpu_ms\"])\n",
    "    overhead_times.append(metrics[\"overhead_ms\"])\n",
    "\n",
    "def summarize(label, data):\n",
    "    return (f\"{label:>10}: \"\n",
    "            f\"mean={stats.mean(data):8.3f} ms | \"\n",
    "            f\"median={stats.median(data):8.3f} ms | \"\n",
    "            f\"min={min(data):8.3f} | max={max(data):8.3f}\")\n",
    "\n",
    "print(f\"\\nResults over {len(cpu_times)} runs (excluding warm-up):\")\n",
    "print(summarize(\"CPU\", cpu_times))\n",
    "print(summarize(\"GPU\", gpu_times))\n",
    "print(summarize(\"Overhead\", overhead_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a small GPU tensor operation to confirm GPU compute works\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.rand((10000, 10000), device=\"cuda\")\n",
    "    y = torch.rand((10000, 10000), device=\"cuda\")\n",
    "    z = torch.mm(x, y)\n",
    "    print(\"‚úÖ GPU matrix multiplication completed successfully.\")\n",
    "    del x, y, z\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping GPU compute test (CUDA not available).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
